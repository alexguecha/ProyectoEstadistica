

 #  Regresion Logíística
# Importar la base: La base se llama Haberman, está relacionada con la 
#                   propensión de padecer Cáncer de mama.

# Base en excel nombrada como: BaseEjemploLogistica
BaseEjemploLogistica<-read.csv("C:/Users/Matematicas/Desktop/MATERIAL REGRESIÓN LOGÍSTICA/BaseEjemploLogistica.csv", sep = ";")
fix(BaseEjemploLogistica)
# ======================================================================



# Crear datos de entrenamiento y validación:

# install.packages('caTools')
library(caTools)
set.seed(88)
split <- sample.split(BaseEjemploLogistica$Status, SplitRatio = 0.75)



# Obtener muestras de entrenamiento y de prueba:
Estado_train <- subset(BaseEjemploLogistica, split == TRUE)
Estado_test <- subset(BaseEjemploLogistica, split == FALSE)




# Ajustando el modelo de Regresión Logística:
model <- glm (Status ~ .-ID, data = Estado_train, family = binomial)
summary(model)

model1 <- glm (Status ~ AgeOper1990 + NodAxilarP, data = Estado_train, family = binomial)
summary(model1)

model2 <- glm (Status ~ AgeOper1990 , data = Estado_train, family = binomial)
summary(model2)

model3 <- glm (Status ~ NodAxilarP, data = Estado_train, family = binomial)
summary(model3)

predict <- predict(model1, type = 'response')
predict2 <- as.data.frame(predict(model1, type = 'response'))
fix(predict2)



# :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
plot(Status ~ AgeOper1990, data = Estado_train, 
     col = "darkorange", pch = "|", ylim = c(-0.2, 1),
     main = "UUsando Regresión Logística par Clasificar")

model2 <- glm (Status ~ Age, data = Estado_train, family = binomial)

abline(h = 0, lty = 3)
abline(h = 1, lty = 3)
abline(h = 0.5, lty = 2)

curve(predict(model2, data.frame(Age = x), type = "response"), 
      add = TRUE, lwd = 3, col = "dodgerblue")
abline(v = -coef(model2)[1] / coef(model2)[2], lwd = 2)
# :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::





# Matriz de Confusion:
table(Estado_train$Status, predict > 0.5)

model

# Curva ROCR
library(ROCR)
ROCRpred <- prediction(predict, Estado_train$Status)
ROCRperf <- performance(ROCRpred, 'tpr','fpr')
plot(ROCRperf, colorize = TRUE, text.adj = c(-0.2,1.7))






#plot glm
library(ggplot2)
ggplot(Estado_train, aes(x=Age, y=predict)) + geom_point() + stat_smooth(method="glm", family="binomial", se=FALSE)

ggplot(Estado_train, aes(x=AgeOper1990, y=predict)) + geom_point() + stat_smooth(method="glm", family="binomial", se=FALSE)

ggplot(Estado_train, aes(x=NodAxilarP, y=predict)) + geom_point() + stat_smooth(method="glm", family="binomial", se=FALSE)




library(ggplot2)
ggplot(Estado_train, aes(x=NodAxilarP, y=predict)) + geom_point() +  stat_smooth(method="glm", method.args=list(family="binomial"), se=FALSE)

ggplot(Estado_train, aes(x=NodAxilarP, y=predict)) + geom_point() +  stat_smooth(method="glm", method.args=list(family=binomial(link="logit")), se=FALSE)




# La curva ROC
library(pROC)
test_prob = predict(model, newdata = Estado_train, type = "response")
test_roc = roc(Estado_train$Status ~ test_prob, plot = TRUE, print.auc = TRUE)

(as.numeric(test_roc$auc))*100




# ===========================================================================
#  NOTAS METODOLÓGICAS
# ===========================================================================
#
# Desempeño del modelo de regresión logística:
# Para evaluar el rendimiento de un modelo de regresión logística, debemos 
# considerar pocas métricas. Independientemente de la herramienta (SAS, R, 
# Python) en la que trabajará, siempre busque:
#  
# 1. El AIC (Criterios de información de Akaike): Es la métrica análoga 
#    del R2 ajustado en la regresión logística. AIC es la medida de 
#    ajuste que penaliza el modelo por el número de coeficientes del mismo. 
#    Por lo tanto, siempre preferimos el modelo con un valor pequeño de AIC.
#
#
# 2. Desviación nula y desviación residual: la desviación nula indica la 
#    respuesta pronosticada por un modelo con nada más que un intercepto. 
#    Si este valor es pequeño, mejor es el modelo. 
#    La desviación residual indica la respuesta predicha por un modelo al 
#    agregar variables independientes. Si este valor es pequeño, mejor es 
#    el modelo.
#
#
#
# 3. Matriz de confusión: no es más que una representación tabular de valores 
#    reales frente a valores pronosticados. Esto nos ayuda a encontrar la 
#    precisión del modelo y evitar el sobreajuste.
  
  
  
  
#  La Curva Característica Operativa (ROC) resume el desempeño del modelo 
# mediante la evaluación de las compensaciones entre la tasa de verdaderos 
# positivos (sensibilidad) y la tasa de falsos positivos(1- especificidad). 
# Para trazar ROC, suponemos p> 0.5 ya que estamos más 
# preocupados por la tasa de éxito. La curva ROC resume el poder predictivo 
# para todos los valores posibles de p> 0.5. El área bajo la curva (ROC), 
# es denominada índice de precisión o índice de concordancia, es una medida 
# de rendimiento perfecto para la curva ROC. 
# Entre más alta sea el área bajo la curva, mejor es el poder de predicción 
# del modelo. 
# La ROC de un modelo predictivo perfecto tiene Verdaderos Positivos igual 
# a 1 y Falsos Positivos igual a 0. Esta curva intenta tocar la esquina 
# superior izquierda del gráfico.







